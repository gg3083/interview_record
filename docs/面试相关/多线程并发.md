# 多线程并发

## 1.synchronized的实现原理以及锁优化？

### synchronized的实现原理

*   synchronized作用于**「方法」**或者**「代码块」**，保证被修饰的代码在同一时间只能被一个线程访问。

*   synchronized修饰代码块时，JVM采用**「monitorenter、monitorexit」**两个指令来实现同步

*   synchronized修饰同步方法时，JVM采用**「ACC##_SYNCHRONIZED」**标记符来实现同步

*   monitorenter、monitorexit或者ACC##_SYNCHRONIZED都是**「基于Monitor实现」**的

*   实例对象里有对象头，对象头里面有Mark Word，Mark Word指针指向了**「monitor」**

*   Monitor其实是一种**「同步工具」**，也可以说是一种**「同步机制」**。

*   在Java虚拟机（HotSpot）中，Monitor是由**「ObjectMonitor实现」**的。ObjectMonitor体现出Monitor的工作原理~


`ObjectMonitor() {
_header       = NULL;
_count        = 0; // 记录线程获取锁的次数
_waiters      = 0,
_recursions   = 0;  //锁的重入次数
_object       = NULL;
_owner        = NULL;  // 指向持有ObjectMonitor对象的线程
_WaitSet      = NULL;  // 处于wait状态的线程，会被加入到_WaitSet
_WaitSetLock  = 0 ;
_Responsible  = NULL ;
_succ         = NULL ;
_cxq          = NULL ;
FreeNext      = NULL ;
_EntryList    = NULL ;  // 处于等待锁block状态的线程，会被加入到该列表
_SpinFreq     = 0 ;
_SpinClock    = 0 ;
OwnerIsThread = 0 ;
}`

ObjectMonitor的几个关键属性 ##_count、##_recursions、##_owner、##_WaitSet、 ##_EntryList 体现了monitor的工作原理 ![](https://user-gold-cdn.xitu.io/2020/7/24/1738189a4358965a?w=1280&h=765&f=png&s=271126)

### 锁优化

在讨论锁优化前，先看看JAVA对象头(32位JVM)中Mark Word的结构图吧~

![](https://user-gold-cdn.xitu.io/2020/7/25/173840a59e8cb91a?w=1406&h=583&f=png&s=101991)

Mark Word存储对象自身的运行数据，如**「哈希码、GC分代年龄、锁状态标志、偏向时间戳（Epoch）」** 等，为什么区分**「偏向锁、轻量级锁、重量级锁」**等几种锁状态呢？

> ❝
>
> 在JDK1.6之前，synchronized的实现直接调用ObjectMonitor的enter和exit，这种锁被称之为**「重量级锁」**。从JDK6开始，HotSpot虚拟机开发团队对Java中的锁进行优化，如增加了适应性自旋、锁消除、锁粗化、轻量级锁和偏向锁等优化策略。
>
> ❞

*   偏向锁：在无竞争的情况下，把整个同步都消除掉，CAS操作都不做。

*   轻量级锁：在没有多线程竞争时，相对重量级锁，减少操作系统互斥量带来的性能消耗。但是，如果存在锁竞争，除了互斥量本身开销，还额外有CAS操作的开销。

*   自旋锁：减少不必要的CPU上下文切换。在轻量级锁升级为重量级锁时，就使用了自旋加锁的方式

*   锁粗化：将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁。


> ❝
>
> 举个例子，买门票进动物园。老师带一群小朋友去参观，验票员如果知道他们是个集体，就可以把他们看成一个整体（锁租化），一次性验票过，而不需要一个个找他们验票。
>
> ❞

*   锁消除:虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行削除。


有兴趣的朋友们可以看看我这篇文章： Synchronized解析——如果你愿意一层一层剥开我的心##[1##]

## 2.ThreadLocal原理，使用注意点，应用场景有哪些？

回答四个主要点：

*   ThreadLocal是什么?

*   ThreadLocal原理

*   ThreadLocal使用注意点

*   ThreadLocal的应用场景


### ThreadLocal是什么?

ThreadLocal，即线程本地变量。如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的一个本地拷贝，多个线程操作这个变量的时候，实际是操作自己本地内存里面的变量，从而起到线程隔离的作用，避免了线程安全问题。

```//创建一个ThreadLocal变量
static ThreadLocal<String> localVariable = new ThreadLocal<>();
```

### ThreadLocal原理

ThreadLocal内存结构图：

![](https://user-gold-cdn.xitu.io/2020/7/26/1738a130b3c6e020?w=1211&h=982&f=png&s=257051) 由结构图是可以看出：

*   Thread对象中持有一个ThreadLocal.ThreadLocalMap的成员变量。

*   ThreadLocalMap内部维护了Entry数组，每个Entry代表一个完整的对象，key是ThreadLocal本身，value是ThreadLocal的泛型值。


对照着几段关键源码来看，更容易理解一点哈~

```public class Thread implements Runnable {
//ThreadLocal.ThreadLocalMap是Thread的属性
ThreadLocal.ThreadLocalMap threadLocals = null;
}
```

ThreadLocal中的关键方法set()和get()

```public void set(T value) {
Thread t = Thread.currentThread(); //获取当前线程t
ThreadLocalMap map = getMap(t);  //根据当前线程获取到ThreadLocalMap
if (map != null)
map.set(this, value); //K，V设置到ThreadLocalMap中
else
createMap(t, value); //创建一个新的ThreadLocalMap
}
public T get() {
Thread t = Thread.currentThread();//获取当前线程t
ThreadLocalMap map = getMap(t);//根据当前线程获取到ThreadLocalMap
if (map != null) {
//由this（即ThreadLoca对象）得到对应的Value，即ThreadLocal的泛型值
ThreadLocalMap.Entry e = map.getEntry(this);
if (e != null) {
@SuppressWarnings("unchecked")
T result = (T)e.value;
return result;
}
}
return setInitialValue();
}
```

ThreadLocalMap的Entry数组

```static class ThreadLocalMap {
static class Entry extends WeakReference<ThreadLocal<?>> {
 /** The value associated with this ThreadLocal. */
 Object value;
 Entry(ThreadLocal<?> k, Object v) {
super(k);
value = v;
}
}
}
```

所以怎么回答**「ThreadLocal的实现原理」**？如下，最好是能结合以上结构图一起说明哈~

> ❝
>
> *   Thread类有一个类型为ThreadLocal.ThreadLocalMap的实例变量threadLocals，即每个线程都有一个属于自己的ThreadLocalMap。
>
> *   ThreadLocalMap内部维护着Entry数组，每个Entry代表一个完整的对象，key是ThreadLocal本身，value是ThreadLocal的泛型值。
>
> *   每个线程在往ThreadLocal里设置值的时候，都是往自己的ThreadLocalMap里存，读也是以某个ThreadLocal作为引用，在自己的map里找对应的key，从而实现了线程隔离。
>
>
> ❞

### ThreadLocal 内存泄露问题

先看看一下的TreadLocal的引用示意图哈，

![](https://user-gold-cdn.xitu.io/2020/7/26/1738b3cf19130e19?w=1804&h=741&f=png&s=99228)

ThreadLocalMap中使用的 key 为 ThreadLocal 的弱引用，如下 ![](https://user-gold-cdn.xitu.io/2020/7/26/1738b1a2f8978e47?w=1052&h=498&f=png&s=48612)

> ❝
>
> 弱引用：只要垃圾回收机制一运行，不管JVM的内存空间是否充足，都会回收该对象占用的内存。
>
> ❞

弱引用比较容易被回收。因此，如果ThreadLocal（ThreadLocalMap的Key）被垃圾回收器回收了，但是因为ThreadLocalMap生命周期和Thread是一样的，它这时候如果不被回收，就会出现这种情况：ThreadLocalMap的key没了，value还在，这就会**「造成了内存泄漏问题」**。

如何**「解决内存泄漏问题」**？使用完ThreadLocal后，及时调用remove()方法释放内存空间。

### ThreadLocal的应用场景

*   数据库连接池

*   会话管理中使用


## 3.synchronized和ReentrantLock的区别？

我记得校招的时候，这道面试题出现的频率还是挺高的~可以从锁的实现、功能特点、性能等几个维度去回答这个问题，

*   **「锁的实现：」** synchronized是Java语言的关键字，基于JVM实现。而ReentrantLock是基于JDK的API层面实现的（一般是lock()和unlock()方法配合try/finally 语句块来完成。）

*   **「性能：」** 在JDK1.6锁优化以前，synchronized的性能比ReenTrantLock差很多。但是JDK6开始，增加了适应性自旋、锁消除等，两者性能就差不多了。

*   **「功能特点：」** ReentrantLock 比 synchronized 增加了一些高级功能，如等待可中断、可实现公平锁、可实现选择性通知。


> ❝
>
> *   ReentrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。
>
> *   ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。
>
> *   synchronized与wait()和notify()/notifyAll()方法结合实现等待/通知机制，ReentrantLock类借助Condition接口与newCondition()方法实现。
>
> *   ReentrantLock需要手工声明来加锁和释放锁，一般跟finally配合释放锁。而synchronized不用手动释放锁。
>
>
> ❞

## 4.说说CountDownLatch与CyclicBarrier区别

*   CountDownLatch：一个或者多个线程，等待其他多个线程完成某件事情之后才能执行;

*   CyclicBarrier：多个线程互相等待，直到到达同一个同步点，再继续一起执行。 ![](https://user-gold-cdn.xitu.io/2020/7/27/1738d9ab805c995c?w=1165&h=785&f=png&s=104903)


举个例子吧：

> ❝
>
> *   CountDownLatch：假设老师跟同学约定周末在公园门口集合，等人齐了再发门票。那么，发门票（这个主线程），需要等各位同学都到齐（多个其他线程都完成），才能执行。
>
> *   CyclicBarrier:多名短跑运动员要开始田径比赛，只有等所有运动员准备好，裁判才会鸣枪开始，这时候所有的运动员才会疾步如飞。
>
>
> ❞

## 5.Fork/Join框架的理解

> ❝
>
> Fork/Join框架是Java7提供的一个用于并行执行任务的框架，是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。
>
> ❞

Fork/Join框架需要理解两个点，**「分而治之」**和**「工作窃取算法」**。

**「分而治之」**

以上Fork/Join框架的定义，就是分而治之思想的体现啦 ![](https://user-gold-cdn.xitu.io/2020/7/27/17390bea64fadb1f?w=1295&h=1006&f=png&s=69986)

**「工作窃取算法」**

把大任务拆分成小任务，放到不同队列执行，交由不同的线程分别执行时。有的线程优先把自己负责的任务执行完了，其他线程还在慢慢悠悠处理自己的任务，这时候为了充分提高效率，就需要工作盗窃算法啦~

![](https://user-gold-cdn.xitu.io/2020/7/27/17390d4b199b668a?w=813&h=576&f=png&s=65266)

工作盗窃算法就是，**「某个线程从其他队列中窃取任务进行执行的过程」**。一般就是指做得快的线程（盗窃线程）抢慢的线程的任务来做，同时为了减少锁竞争，通常使用双端队列，即快线程和慢线程各在一端。

## 6.为什么我们调用start()方法时会执行run()方法，为什么我们不能直接调用run()方法？

看看Thread的start方法说明哈~

```java
/**
* Causes this thread to begin execution; the Java Virtual Machine
* calls the <code>run</code> method of this thread.
* <p>
* The result is that two threads are running concurrently: the
* current thread (which returns from the call to the
* <code>start</code> method) and the other thread (which executes its
* <code>run</code> method).
* <p>
* It is never legal to start a thread more than once.
* In particular, a thread may not be restarted once it has completed
* execution.
*
* @exception  IllegalThreadStateException  if the thread was already
*               started.
* @see        #run()
* @see        #stop()
*/
public synchronized void start() {
......
}
```

JVM执行start方法，会另起一条线程执行thread的run方法，这才起到多线程的效果~ **「为什么我们不能直接调用run()方法？」** 如果直接调用Thread的run()方法，其方法还是运行在主线程中，没有起到多线程效果。

## 7.CAS？CAS 有什么缺陷，如何解决？

CAS,Compare and Swap，比较并交换；

> ❝
>
> CAS 涉及3个操作数，内存地址值V，预期原值A，新值B； 如果内存位置的值V与预期原A值相匹配，就更新为新值B，否则不更新
>
> ❞

CAS有什么缺陷？

![](https://user-gold-cdn.xitu.io/2020/7/28/17392a38b3e75683?w=804&h=431&f=png&s=46436)

**「ABA 问题」**

> ❝
>
> 并发环境下，假设初始条件是A，去修改数据时，发现是A就会执行修改。但是看到的虽然是A，中间可能发生了A变B，B又变回A的情况。此时A已经非彼A，数据即使成功修改，也可能有问题。
>
> ❞

可以通过AtomicStampedReference**「解决ABA问题」**，它，一个带有标记的原子引用类，通过控制变量值的版本来保证CAS的正确性。

**「循环时间长开销」**

> ❝
>
> 自旋CAS，如果一直循环执行，一直不成功，会给CPU带来非常大的执行开销。
>
> ❞

很多时候，CAS思想体现，是有个自旋次数的，就是为了避开这个耗时问题~

**「只能保证一个变量的原子操作。」**

> ❝
>
> CAS 保证的是对一个变量执行操作的原子性，如果对多个变量操作时，CAS 目前无法直接保证操作的原子性的。
>
> ❞

可以通过这两个方式解决这个问题：

> ❝
>
> *   使用互斥锁来保证原子性；
>
> *   将多个变量封装成对象，通过AtomicReference来保证原子性。
>
>
> ❞

有兴趣的朋友可以看看我之前的这篇实战文章哈~ CAS乐观锁解决并发问题的一次实践##[2##]

## 9.如何保证多线程下i++ 结果正确？

![](https://user-gold-cdn.xitu.io/2020/7/28/17392b5e8436976e?w=935&h=464&f=png&s=55515)

*   使用循环CAS，实现i++原子操作

*   使用锁机制，实现i++原子操作

*   使用synchronized，实现i++原子操作


没有代码demo，感觉是没有灵魂的~ 如下：

```/**
*  @Author 捡田螺的小男孩
   */
   public class AtomicIntegerTest {
   private static AtomicInteger atomicInteger = new AtomicInteger(0);
   public static void main(String[] args) throws InterruptedException {
   testIAdd();
   }
   private static void testIAdd() throws InterruptedException {
   //创建线程池
   ExecutorService executorService = Executors.newFixedThreadPool(2);
   for (int i = 0; i < 1000; i++) {
   executorService.execute(() -> {
   for (int j = 0; j < 2; j++) {
   //自增并返回当前值
   int andIncrement = atomicInteger.incrementAndGet();
   System.out.println("线程:" + Thread.currentThread().getName() + " count=" + andIncrement);
   }
   });
   }
   executorService.shutdown();
   Thread.sleep(100);
   System.out.println("最终结果是 ：" + atomicInteger.get());
   }
   }
```

运行结果：

`...
线程:pool-1-thread-1 count=1997
线程:pool-1-thread-1 count=1998
线程:pool-1-thread-1 count=1999
线程:pool-1-thread-2 count=315
线程:pool-1-thread-2 count=2000
最终结果是 ：2000`

## 10.如何检测死锁？怎么预防死锁？死锁四个必要条件

死锁是指多个线程因竞争资源而造成的一种互相等待的僵局。如图感受一下： ![](https://user-gold-cdn.xitu.io/2020/7/28/17392c9774168d4c?w=1250&h=830&f=png&s=186643) **「死锁的四个必要条件：」**

*   互斥：一次只有一个进程可以使用一个资源。其他进程不能访问已分配给其他进程的资源。

*   占有且等待：当一个进程在等待分配得到其他资源时，其继续占有已分配得到的资源。

*   非抢占：不能强行抢占进程中已占有的资源。

*   循环等待：存在一个封闭的进程链，使得每个资源至少占有此链中下一个进程所需要的一个资源。


**「如何预防死锁？」**

*   加锁顺序（线程按顺序办事）

*   加锁时限 （线程请求所加上权限，超时就放弃，同时释放自己占有的锁）

*   死锁检测


## 11、为什么要用线程池？Java的线程池内部机制，参数作用，几种工作阻塞队列，线程池类型以及使用场景
回答这些点：
- 为什么要用线程池？
- Java的线程池原理
- 线程池核心参数
- 几种工作阻塞队列
- 线程池使用不当的问题
- 线程池类型以及使用场景

### 为什么要用线程池？
线程池：一个管理线程的池子。
- 管理线程，避免增加创建线程和销毁线程的资源损耗。
- 提高响应速度。
- 重复利用。

### Java的线程池执行原理
![](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/efe9ed82093e4c8bab768eac79dffed3~tplv-k3u1fbpfcp-zoom-1.image)
为了形象描述线程池执行，打个比喻：
- 核心线程比作公司正式员工
- 非核心线程比作外包员工
- 阻塞队列比作需求池
- 提交任务比作提需求
  ![](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6ed3df3db91941e9b8d3e1078fdd02b5~tplv-k3u1fbpfcp-zoom-1.image)

### 线程池核心参数
```
public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize,
   long keepAliveTime,
   TimeUnit unit,
   BlockingQueue<Runnable> workQueue,
   ThreadFactory threadFactory,
   RejectedExecutionHandler handler) 
```
- corePoolSize： 线程池核心线程数最大值
- maximumPoolSize： 线程池最大线程数大小
- keepAliveTime： 线程池中非核心线程空闲的存活时间大小
- unit： 线程空闲存活时间单位
- workQueue： 存放任务的阻塞队列
- threadFactory： 用于设置创建线程的工厂，可以给创建的线程设置有意义的名字，可方便排查问题。
- handler：线城池的饱和策略事件，主要有四种类型拒绝策略。

**四种拒绝策略**
- AbortPolicy(抛出一个异常，默认的)
- DiscardPolicy(直接丢弃任务)
- DiscardOldestPolicy（丢弃队列里最老的任务，将当前这个任务继续提交给线程池）
- CallerRunsPolicy（交给线程池调用所在的线程进行处理)

### 几种工作阻塞队列

- ArrayBlockingQueue（用数组实现的有界阻塞队列，按FIFO排序量）
- LinkedBlockingQueue（基于链表结构的阻塞队列，按FIFO排序任务，容量可以选择进行设置，不设置的话，将是一个无边界的阻塞队列）
- DelayQueue（一个任务定时周期的延迟执行的队列）
- PriorityBlockingQueue（具有优先级的无界阻塞队列）
- SynchronousQueue（一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态）


### 线程池使用不当的问题
线程池适用不当可能导致内存飙升问题哦

有兴趣可以看我这篇文章哈:[源码角度分析-newFixedThreadPool线程池导致的内存飙升问题](https://juejin.im/post/6844903930502070285)

### 线程池类型以及使用场景
- newFixedThreadPool
> 适用于处理CPU密集型的任务，确保CPU在长期被工作线程使用的情况下，尽可能的少的分配线程，即适用执行长期的任务。
- newCachedThreadPool
> 用于并发执行大量短期的小任务。
- newSingleThreadExecutor
> 适用于串行执行任务的场景，一个任务一个任务地执行。
- newScheduledThreadPool
> 周期性执行任务的场景，需要限制线程数量的场景
- newWorkStealingPool
> 建一个含有足够多线程的线程池，来维持相应的并行级别，它会通过工作窃取的方式，使得多核的 CPU 不会闲置，总会有活着的线程让 CPU 去运行,本质上就是一个 ForkJoinPool。)


有兴趣可以看我这篇文章哈:[面试必备：Java线程池解析](https://juejin.im/post/6844903889678893063)

## 12、谈谈volatile关键字的理解
volatile是面试官非常喜欢问的一个问题，可以回答以下这几点：
- vlatile变量的作用
- 现代计算机的内存模型（嗅探技术，MESI协议，总线）
- Java内存模型（JMM）
- 什么是可见性？
- 指令重排序
- volatile的内存语义
- as-if-serial
- Happens-before
- volatile可以解决原子性嘛？为什么？
- volatile底层原理，如何保证可见性和禁止指令重排（内存屏障）

### vlatile变量的作用？
- 保证变量对所有线程可见性
- 禁止指令重排
### 现代计算机的内存模型
![](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b4bb647387f34af09ce1096ef916be9a~tplv-k3u1fbpfcp-zoom-1.image)
- 其中高速缓存包括L1，L2，L3缓存~
- 缓存一致性协议，可以了解MESI协议
- 总线（Bus）是计算机各种功能部件之间传送信息的公共通信干线，CPU和其他功能部件是通过总线通信的。
- 处理器使用嗅探技术保证它的内部缓存、系统内存和其他处理器的缓存数据在总线上保持一致。
### Java内存模型（JMM）
![](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/275f5b038d1d4e9ba308ab129df4aef3~tplv-k3u1fbpfcp-zoom-1.image)

### 什么是可见性？
可见性就是当一个线程 修改一个共享变量时，另外一个线程能读到这个修改的值。

### 指令重排序
指令重排是指在程序执行过程中,为了提高性能, 编译器和CPU可能会对指令进行重新排序。
![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/063d5ff09b604add8bbb25b3d9346169~tplv-k3u1fbpfcp-zoom-1.image)

### volatile的内存语义
- 当写一个 volatile 变量时，JMM 会把该线程对应的本地内存中的共享变量值刷新到主内存。
- 当读一个 volatile 变量时，JMM 会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。

### as-if-serial
如果在本线程内观察，所有的操作都是有序的；即不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不会被改变。
```
double pi  = 3.14;    //A
double r   = 1.0;     //B
double area = pi * r * r; //C
```
步骤C依赖于步骤A和B，因为指令重排的存在，程序执行顺讯可能是A->B->C,也可能是B->A->C,但是C不能在A或者B前面执行，这将违反as-if-serial语义。
![](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/50dd857cc9d94ec8853531fdeae52497~tplv-k3u1fbpfcp-zoom-1.image)

### Happens-before
Java语言中，有一个先行发生原则（happens-before）：
- **程序次序规则**：在一个线程内，按照控制流顺序，书写在前面的操作先行发生于书写在后面的操作。
- **管程锁定规则**：一个unLock操作先行发生于后面对同一个锁额lock操作
- **volatile变量规则**：对一个变量的写操作先行发生于后面对这个变量的读操作
- **线程启动规则**：Thread对象的start()方法先行发生于此线程的每个一个动作
- **线程终止规则**：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行
- **线程中断规则**：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生
- **对象终结规则**：一个对象的初始化完成先行发生于他的finalize()方法的开始
- **传递性**：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C

### volatile可以解决原子性嘛？为什么？
不可以，可以直接举i++那个例子，原子性需要synchronzied或者lock保证
```
public class Test {
    public volatile int race = 0;
     
    public void increase() {
        race++;
    }
     
    public static void main(String[] args) {
        final Test test = new Test();
        for(int i=0;i<10;i++){
            new Thread(){
                public void run() {
                    for(int j=0;j<100;j++)
                        test.increase();
                };
            }.start();
        }
        
        //等待所有累加线程结束
        while(Thread.activeCount()>1)  
            Thread.yield();
        System.out.println(test.race);
    }
}

```

### volatile底层原理，如何保证可见性和禁止指令重排（内存屏障）

volatile 修饰的变量，转成汇编代码，会发现多出一个lock前缀指令。lock指令相当于一个内存屏障，它保证以下这几点：
- 1.重排序时不能把后面的指令重排序到内存屏障之前的位置
- 2.将本处理器的缓存写入内存
- 3.如果是写入动作，会导致其他处理器中对应的缓存无效。

2、3点保证可见性，第1点禁止指令重排~

有兴趣的朋友可以看我这篇文章哈:[Java程序员面试必备：Volatile全方位解析](https://juejin.im/post/6859390417314512909)


## 13、AQS组件，实现原理
AQS，即AbstractQueuedSynchronizer，是构建锁或者其他同步组件的基础框架，它使用了一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作。可以回答以下这几个关键点哈：
- state 状态的维护。
- CLH队列
- ConditionObject通知
- 模板方法设计模式
- 独占与共享模式。
- 自定义同步器。
- AQS全家桶的一些延伸，如：ReentrantLock等。

### state 状态的维护

- state，int变量，锁的状态，用volatile修饰，保证多线程中的可见性。
- getState()和setState()方法采用final修饰，限制AQS的子类重写它们两。
- compareAndSetState（）方法采用乐观锁思想的CAS算法操作确保线程安全,保证状态
  设置的原子性。

对CAS有兴趣的朋友，可以看下我这篇文章哈~
[CAS乐观锁解决并发问题的一次实践](https://juejin.im/post/6844903869340712967#comment)


### CLH队列
![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3f37b908ad9b482fb60de6478817a7dc~tplv-k3u1fbpfcp-zoom-1.image)

> **CLH(Craig, Landin, and Hagersten locks) 同步队列** 是一个FIFO双向队列，其内部通过节点head和tail记录队首和队尾元素，队列元素的类型为Node。AQS依赖它来完成同步状态state的管理，当前线程如果获取同步状态失败时，AQS则会将当前线程已经等待状态等信息构造成一个节点（Node）并将其加入到CLH同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点唤醒（公平锁），使其再次尝试获取同步状态。


### ConditionObject通知

我们都知道，synchronized控制同步的时候，可以配合Object的wait()、notify()，notifyAll() 系列方法可以实现等待/通知模式。而Lock呢？它提供了条件Condition接口，配合await(),signal(),signalAll() 等方法也可以实现等待/通知机制。ConditionObject实现了Condition接口，给AQS提供条件变量的支持 。

![](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/385e31246e8c4e1e8e8a9dacb183da74~tplv-k3u1fbpfcp-zoom-1.image)

ConditionObject队列与CLH队列的爱恨情仇：

- 调用了await()方法的线程，会被加入到conditionObject等待队列中，并且唤醒CLH队列中head节点的下一个节点。
- 线程在某个ConditionObject对象上调用了singnal()方法后，等待队列中的firstWaiter会被加入到AQS的CLH队列中，等待被唤醒。
- 当线程调用unLock()方法释放锁时，CLH队列中的head节点的下一个节点(在本例中是firtWaiter)，会被唤醒。


### 模板方法设计模式
什么是模板设计模式？
> 在一个方法中定义一个算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以在不改变算法结构的情况下，重新定义算法中的某些步骤。

AQS的典型设计模式就是模板方法设计模式啦。AQS全家桶（ReentrantLock，Semaphore）的衍生实现，就体现出这个设计模式。如AQS提供tryAcquire，tryAcquireShared等模板方法，给子类实现自定义的同步器。

### 独占与共享模式
- 独占式: 同一时刻仅有一个线程持有同步状态，如ReentrantLock。又可分为公平锁和非公平锁。
- 共享模式:多个线程可同时执行，如Semaphore/CountDownLatch等都是共享式的产物。

### 自定义同步器

你要实现自定义锁的话，首先需要确定你要实现的是独占锁还是共享锁，定义原子变量state的含义，再定义一个内部类去继承AQS，重写对应的模板方法即可啦

### AQS全家桶的一些延伸。
Semaphore，CountDownLatch，ReentrantLock

可以看下之前我这篇文章哈，[AQS解析与实战](https://juejin.im/post/6844903903188746247)

## 14、什么是多线程环境下的伪共享
- 什么是伪共享
- 如何解决伪共享问题

### 什么是伪共享
伪共享定义？
> CPU的缓存是以缓存行(cache line)为单位进行缓存的，当多个线程修改相互独立的变量，而这些变量又处于同一个缓存行时就会影响彼此的性能。这就是伪共享

现代计算机计算模型，大家都有印象吧？我之前这篇文章也有讲过，有兴趣可以看一下哈，[Java程序员面试必备：Volatile全方位解析](https://juejin.im/post/6859390417314512909)

![](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a3bcae0d0fb44b1b9fb2db5093e6dd5d~tplv-k3u1fbpfcp-zoom-1.image)
- CPU执行速度比内存速度快好几个数量级，为了提高执行效率，现代计算机模型演变出CPU、缓存（L1，L2，L3），内存的模型。
- CPU执行运算时，如先从L1缓存查询数据，找不到再去L2缓存找，依次类推，直到在内存获取到数据。
- 为了避免频繁从内存获取数据，聪明的科学家设计出缓存行，缓存行大小为64字节。

也正是因为缓存行，就导致伪共享问题的存在，如图所示：
![](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/886ab0227a174842a2976581472eec06~tplv-k3u1fbpfcp-zoom-1.image)

假设数据a、b被加载到同一个缓存行。
- 当线程1修改了a的值，这时候CPU1就会通知其他CPU核，当前缓存行（Cache line）已经失效。
- 这时候，如果线程2发起修改b，因为缓存行已经失效了，所以**core2 这时会重新从主内存中读取该 Cache line 数据**。读完后，因为它要修改b的值，那么CPU2就通知其他CPU核，当前缓存行（Cache line）又已经失效。
- 酱紫，如果同一个Cache line的内容被多个线程读写，就很容易产生相互竞争，频繁回写主内存，会大大降低性能。


### 如何解决伪共享问题
既然伪共享是因为相互独立的变量存储到相同的Cache line导致的，一个缓存行大小是64字节。那么，我们就可以**使用空间换时间**，即数据填充的方式，把独立的变量分散到不同的Cache line~

共享内存demo例子:
```
public class FalseShareTest  {

    public static void main(String[] args) throws InterruptedException {
        Rectangle rectangle = new Rectangle();
        long beginTime = System.currentTimeMillis();
        Thread thread1 = new Thread(() -> {
            for (int i = 0; i < 100000000; i++) {
                rectangle.a = rectangle.a + 1;
            }
        });

        Thread thread2 = new Thread(() -> {
            for (int i = 0; i < 100000000; i++) {
                rectangle.b = rectangle.b + 1;
            }
        });

        thread1.start();
        thread2.start();
        thread1.join();
        thread2.join();

        System.out.println("执行时间" + (System.currentTimeMillis() - beginTime));
    }

}

class Rectangle {
    volatile long a;
    volatile long b;
}
```

运行结果：
```
执行时间2815
```
一个long类型是8字节，我们在变量a和b之间不上7个long类型变量呢，输出结果是啥呢？如下：
```
class Rectangle {
    volatile long a;
    long a1,a2,a3,a4,a5,a6,a7;
    volatile long b;
}
```
运行结果：
```
执行时间1113
```
可以发现利用填充数据的方式，让读写的变量分割到不同缓存行，可以很好挺高性能~


## 15、 说一下 Runnable和 Callable有什么区别？
- Callable接口方法是call()，Runnable的方法是run()；
- Callable接口call方法有返回值，支持泛型，Runnable接口run方法无返回值。
- Callable接口call()方法允许抛出异常；而Runnable接口run()方法不能继续上抛异常；

```
@FunctionalInterface
public interface Callable<V> {
    /**
     * 支持泛型V，有返回值，允许抛出异常
     */
    V call() throws Exception;
}

@FunctionalInterface
public interface Runnable {
    /**
     *  没有返回值，不能继续上抛异常
     */
    public abstract void run();
}

```

看下demo代码吧，这样应该好理解一点哈~
```
/*
 *  @Author 捡田螺的小男孩
 *  @date 2020-08-18
 */
public class CallableRunnableTest {

    public static void main(String[] args) {
        ExecutorService executorService = Executors.newFixedThreadPool(5);

        Callable <String> callable =new Callable<String>() {
            @Override
            public String call() throws Exception {
                return "你好，callable";
            }
        };

        //支持泛型
        Future<String> futureCallable = executorService.submit(callable);

        try {
            System.out.println(futureCallable.get());
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (ExecutionException e) {
            e.printStackTrace();
        }

        Runnable runnable = new Runnable() {
            @Override
            public void run() {
                System.out.println("你好呀,runnable");
            }
        };

        Future<?> futureRunnable = executorService.submit(runnable);
        try {
            System.out.println(futureRunnable.get());
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (ExecutionException e) {
            e.printStackTrace();
        }
        executorService.shutdown();

    }
}
```
运行结果：
```
你好，callable
你好呀,runnable
null
```


## 16、wait(),notify()和suspend(),resume()之间的区别

- wait() 使得线程进入阻塞等待状态，并且释放锁
- notify()唤醒一个处于等待状态的线程，它一般跟wait（）方法配套使用。
- suspend()使得线程进入阻塞状态，并且不会自动恢复，必须对应的resume() 被调用，才能使得线程重新进入可执行状态。suspend()方法很容易引起死锁问题。
- resume()方法跟suspend()方法配套使用。

**suspend()不建议使用**,suspend()方法在调用后，线程不会释放已经占有的资 源（比如锁），而是占有着资源进入睡眠状态，这样容易引发死锁问题。


## 17.Condition接口及其实现原理
- Condition接口与Object监视器方法对比
- Condition接口使用demo
- Condition实现原理

### Condition接口与Object监视器方法对比
Java对象（Object），提供wait()、notify()，notifyAll() 系列方法，配合synchronized，可以实现等待/通知模式。而Condition接口配合Lock，通过await(),signal(),signalAll() 等方法，也可以实现类似的等待/通知机制。

| 对比项 | 对象监视方法| Condition |
|-----|-----|------|
| 前置条件 | 获得对象的锁  | 调用Lock.lock()获取锁,调用Lock.newCondition()获得Condition对象|
| 调用方式 | 直接调用，object.wait()  | 直接调用，condition.await() |
| 等待队列数 | 1个   | 多个 |
| 当前线程释放锁并进入等待状态 | 支持  | 支持 |
| 在等待状态中不响应中断 | 不支持  | 支持 |
| 当前线程释放锁并进入超时等待状态| 支持  | 支持 |
| 当前线程释放锁并进入等待状态到将来的某个时间| 不支持  | 支持 |
| 唤醒等待队列中的一个线程| 支持  | 支持 |
| 唤醒等待队列中的全部线程| 支持  | 支持 |


### Condition接口使用demo
```
public class ConditionTest {
    Lock lock = new ReentrantLock();
    Condition condition = lock.newCondition();

    public void conditionWait() throws InterruptedException {
        lock.lock();
        try {
            condition.await();
        } finally {
            lock.unlock();
        }
    }

    public void conditionSignal() throws InterruptedException {
        lock.lock();
        try {
            condition.signal();
        } finally {
            lock.unlock();
        }
    }
}

```
### Condition实现原理
其实，同步队列和等待队列中节点类型都是同步器的静态内部类 AbstractQueuedSynchronizer.Node，接下来我们图解一下Condition的实现原理~

**等待队列的基本结构图**
![](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a6f62d7c11ea4907b84924c4a02cee7f~tplv-k3u1fbpfcp-zoom-1.image)
> 一个Condition包含一个等待队列，Condition拥有首节点（firstWaiter）和尾节点 （lastWaiter）。当前线程调用Condition.await()方法，将会以当前线程构造节点，并将节点从尾部加入等待队

**AQS 结构图**

ConditionI是跟Lock一起结合使用的，底层跟同步器（AQS）相关。同步器拥有一个同步队列和多个等待队列~
![](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f342c548da8c42d6a60a0c19aeee8489~tplv-k3u1fbpfcp-zoom-1.image)


**等待**

![](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/677bf2a7edd8447b9f21e626e6667aa3~tplv-k3u1fbpfcp-zoom-1.image)
>  当调用await()方法时，相当于同步队列的首节点（获取了锁的节点）移动到Condition的等待队列中。


**通知**

![](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bac0705fa308413b97eed7a9d8b938c6~tplv-k3u1fbpfcp-zoom-1.image)
> 调用Condition的signal()方法，将会唤醒在等待队列中等待时间最长的节点（首节点），在
唤醒节点之前，会将节点移到同步队列中。


## 18、线程池如何调优，最大数目如何确认？

在《Java Concurrency in Practice》一书中，有一个评估线程池线程大小的公式
>  **Nthreads=Ncpu*Ucpu*(1+w/c)**
>
> - Ncpu = CPU总核数
- Ucpu =cpu使用率，0~1
- W/C=等待时间与计算时间的比率

假设cpu 100%运转，则公式为
```
Nthreads=Ncpu*(1+w/c)
```

**估算的话，酱紫：**
- 如果是**IO密集型应用**（如数据库数据交互、文件上传下载、网络数据传输等等），IO操作一般比较耗时，等待时间与计算时间的比率（w/c）会大于1，所以最佳线程数估计就是 Nthreads=Ncpu*（1+1）= 2Ncpu 。
- 如果是**CPU密集型应用**（如算法比较复杂的程序），最理想的情况，没有等待，w=0，Nthreads=Ncpu。又对于计算密集型的任务，在拥有N个处理器的系统上，当线程池的大小为N+1时，通常能实现最优的效率。所以 Nthreads = Ncpu+1

有具体指参考呢？举个例子
> 比如平均每个线程CPU运行时间为0.5s，而线程等待时间（非CPU运行时间，比如IO）为1.5s，CPU核心数为8，那么根据上面这个公式估算得到：线程池大小=(1+1.5/05)*8 =32。

参考了网上这篇文章，写得很棒，有兴趣的朋友可以去看一下哈：
- [根据CPU核心数确定线程池并发线程数](https://www.cnblogs.com/dennyzhangdd/p/6909771.html)

## 19、 假设有T1、T2、T3三个线程，你怎样保证T2在T1执行完后执行，T3在T2执行完后执行？

可以使用**join方法**解决这个问题。比如在线程A中，调用线程B的join方法表示的意思就是**：A等待B线程执行完毕后（释放CPU执行权），在继续执行。**

代码如下：
```
public class ThreadTest {

    public static void main(String[] args) {

        Thread spring = new Thread(new SeasonThreadTask("春天"));
        Thread summer = new Thread(new SeasonThreadTask("夏天"));
        Thread autumn = new Thread(new SeasonThreadTask("秋天"));

        try
        {
            //春天线程先启动
            spring.start();
            //主线程等待线程spring执行完，再往下执行
            spring.join();
            //夏天线程再启动
            summer.start();
            //主线程等待线程summer执行完，再往下执行
            summer.join();
            //秋天线程最后启动
            autumn.start();
            //主线程等待线程autumn执行完，再往下执行
            autumn.join();
        } catch (InterruptedException e)
        {
            e.printStackTrace();
        }
    }
}

class SeasonThreadTask implements Runnable{

    private String name;

    public SeasonThreadTask(String name){
        this.name = name;
    }

    @Override
    public void run() {
        for (int i = 1; i <4; i++) {
            System.out.println(this.name + "来了: " + i + "次");
            try {
                Thread.sleep(100);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}

```

运行结果：
```
春天来了: 1次
春天来了: 2次
春天来了: 3次
夏天来了: 1次
夏天来了: 2次
夏天来了: 3次
秋天来了: 1次
秋天来了: 2次
秋天来了: 3次
```
## 20. LockSupport作用是？

- LockSupport作用
- park和unpark，与wait，notify的区别
- Object blocker作用？

LockSupport是个工具类，它的主要作用是挂起和唤醒线程， 该工具类是创建锁和其他同步类的基础。

```
public static void park(); //挂起当前线程，调用unpark(Thread thread)或者当前线程被中断，才能从park方法返回
public static void parkNanos(Object blocker, long nanos);  // 挂起当前线程，有超时时间的限制
public static void parkUntil(Object blocker, long deadline); // 挂起当前线程，直到某个时间
public static void park(Object blocker); //挂起当前线程
public static void unpark(Thread thread); // 唤醒当前thread线程
```

看个例子吧：
```
public class LockSupportTest {

    public static void main(String[] args) {

        CarThread carThread = new CarThread();
        carThread.setName("劳斯劳斯");
        carThread.start();

        try {
            Thread.currentThread().sleep(2000);
            carThread.park();
            Thread.currentThread().sleep(2000);
            carThread.unPark();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }

    static class CarThread extends Thread{

        private boolean isStop = false;

        @Override
        public void run() {

            System.out.println(this.getName() + "正在行驶中");

            while (true) {

                if (isStop) {
                    System.out.println(this.getName() + "车停下来了");
                    LockSupport.park(); //挂起当前线程
                }
                System.out.println(this.getName() + "车还在正常跑");

                try {
                    Thread.sleep(1000L);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }

            }
        }

        public void park() {
            isStop = true;
            System.out.println("停车啦，检查酒驾");

        }

        public void unPark(){
            isStop = false;
            LockSupport.unpark(this); //唤醒当前线程
            System.out.println("老哥你没酒驾，继续开吧");
        }

    }
}

```
运行结果：
```
劳斯劳斯正在行驶中
劳斯劳斯车还在正常跑
劳斯劳斯车还在正常跑
停车啦，检查酒驾
劳斯劳斯车停下来了
老哥你没酒驾，继续开吧
劳斯劳斯车还在正常跑
劳斯劳斯车还在正常跑
劳斯劳斯车还在正常跑
劳斯劳斯车还在正常跑
劳斯劳斯车还在正常跑
劳斯劳斯车还在正常跑
```

LockSupport的park和unpark的实现，有点类似wait和notify的功能。但是
> - park不需要获取对象锁
> - 中断的时候park不会抛出InterruptedException异常，需要在park之后自行判断中断状态
> - 使用park和unpark的时候，可以不用担心park的时序问题造成死锁
> - LockSupport不需要在同步代码块里
> - unpark却可以唤醒一个指定的线程，notify只能随机选择一个线程唤醒

Object blocker作用？
> 方便在线程dump的时候看到具体的阻塞对象的信息。
